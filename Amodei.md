Le directeur d'Anthropic s'exprime sur l'IA : « Nous ne savons pas si les modèles sont conscients »
Dario Amodei partage ses prédictions utopiques — et dystopiques — à court terme concernant l'intelligence artificielle.
12 février 2026
M. Douthat est chroniqueur et animateur du podcast « Interesting Times ».
Les maîtres de l'intelligence artificielle sont-ils du côté de l'humanité ? C'est la question essentielle que j'ai posée à mon invité de cette semaine. Dario Amodei est le PDG d'Anthropic, l'une des entreprises d'IA à la croissance la plus rapide. Il est quelque peu utopiste quant aux bienfaits potentiels de la technologie qu'il déploie à l'échelle mondiale. Mais il entrevoit également de graves dangers et des bouleversements inévitables.
Le directeur d'Anthropic s'exprime sur l'IA : « Nous ne savons pas si les modèles sont conscients »
Dario Amodei partage ses prédictions utopiques — et dystopiques — concernant l'avenir proche de l'intelligence artificielle.
e lecture
Douthat : Vous êtes donc, chose assez inhabituelle pour un PDG du secteur technologique, un essayiste. Vous avez écrit deux longs essais très intéressants sur les promesses et les dangers de l’intelligence artificielle. Nous allons justement aborder ces dangers dans cette conversation, mais il me semblait judicieux de commencer par les promesses et la vision optimiste – voire utopique – que vous avez exposée il y a quelques années dans un essai intitulé « Machines de grâce bienveillante ». Nous reviendrons sur ce titre à la fin.
Mais je pense que beaucoup de gens découvrent l'actualité de l'IA à travers des titres annonçant une véritable hécatombe d'emplois intellectuels, ce genre de choses. Parfois, vos propres déclarations ont contribué à alimenter ces prédictions.
Amodei : Parfois, ce sont mes propres citations. Oui.
Douthat : Et je pense qu’il existe une intuition répandue selon laquelle « À quoi sert l’IA ? » est partagée par beaucoup.
Alors pourquoi ne pas répondre à cette question, pour commencer : si tout se passe à merveille au cours des cinq ou dix prochaines années, à quoi servira l’IA ?
Amodei : Oui, pour vous donner un peu de contexte, avant de travailler dans l’IA, avant même de travailler dans le secteur technologique, j’étais biologiste. J’ai d’abord travaillé en neurosciences computationnelles, puis à la faculté de médecine de Stanford sur la recherche de biomarqueurs protéiques du cancer, afin d’améliorer le diagnostic et le traitement de cette maladie.
L'une des observations les plus marquantes de mon expérience dans ce domaine a été son incroyable complexité. Chaque protéine possède un niveau d'expression localisé au sein de chaque cellule. Mesurer le niveau global, c'est-à-dire le niveau dans chaque cellule, ne suffit pas. Il faut mesurer le niveau dans une partie spécifique de la cellule, ainsi que celui des autres protéines avec lesquelles elle interagit ou forme des complexes.
Et j'avais cette impression : « Mon Dieu, c'est trop compliqué pour les humains. » Nous progressons sur tous ces problèmes de biologie et de médecine, mais nous progressons relativement lentement.
Ce qui m'a attiré vers le domaine de l'IA, c'est cette idée : pouvons-nous progresser plus rapidement ?
Écoutez, cela fait longtemps que nous essayons d'appliquer l'IA et les techniques d'apprentissage automatique à la biologie. Généralement, elles servent à analyser des données. Mais à mesure que l'IA devient vraiment puissante, je pense qu'il est temps de repenser son approche. Il faudrait considérer l'IA comme un outil permettant au biologiste de mener à bien l'ensemble du processus, de A à Z. Cela implique notamment de proposer des expériences et de concevoir de nouvelles techniques.
J'ai une section où j'explique que les progrès en biologie sont en grande partie dus à un nombre relativement restreint de découvertes qui nous permettent de mesurer, d'accéder à ou d'intervenir sur des éléments de l'infiniment petit. Nombre de ces techniques sont le fruit du hasard. CRISPR, une technologie d'édition génique, a été inventée suite à la découverte, lors d'une réunion sur le système immunitaire bactérien, d'un lien établi avec les travaux menés en thérapie génique. Ce lien aurait pu être établi il y a 30 ans.
Dès lors, la question se pose : l’IA pourrait-elle accélérer tous ces progrès ? Pourrions-nous réellement guérir le cancer ? La maladie d’Alzheimer ? Les maladies cardiaques ? Et, plus subtilement, pourrions-nous agir sur certains troubles psychologiques – dépression, bipolarité ? Dans la mesure où ils ont une origine biologique, ce qui, à mon avis, est le cas, au moins en partie.
Alors, je développe cet argument : Eh bien, à quelle vitesse cela pourrait-il aller si nous avions ces intelligences capables de faire à peu près n'importe quoi ?
Douthat : Je voudrais vous interrompre ici, car l’un des aspects intéressants de votre argumentation dans cet essai est que ces intelligences n’ont pas besoin d’être de cette sorte de superintelligence divine et maximale dont on parle souvent dans les débats sur l’IA. Vous dites en substance que si nous pouvons atteindre une intelligence forte au niveau des performances humaines optimales…
Amodei : Performance humaine maximale, oui.
Douthat : Et ensuite, multipliez cela par quoi ? Votre expression est « un pays de génies ».
Amodei : Un pays – avec 100 millions d’individus. Chacun pourrait avoir une formation légèrement différente ou s’attaquer à un problème différent. La diversification et l’expérimentation présentent des avantages, c’est certain.
Douthat : Donc, pas besoin d’avoir le Dieu Machine dans son intégralité. Il suffit d’avoir 100 millions de génies.
Amodei : Il n’est pas nécessaire de posséder la Machine divine dans son intégralité. Et en effet, il y a des points sur lesquels je me demande si la Machine divine serait réellement plus efficace que 100 millions de génies.
J'ai développé le concept de la diminution des rendements de l'intelligence. Les économistes parlent de la productivité marginale des terres et du travail ; on n'a jamais réfléchi à la productivité marginale de l'intelligence. Or, si l'on considère certains problèmes en biologie, on constate qu'à un certain niveau, il faut interagir avec le monde. À un certain niveau, il faut expérimenter. À un certain niveau, il faut se conformer aux lois, voire les modifier, pour que les médicaments soient autorisés par le système réglementaire. Il existe donc un rythme limité pour que ces changements puissent se produire.
Il existe certes des domaines, comme les échecs ou le go, où le potentiel d'intelligence est extrêmement élevé. Mais je pense que le monde réel impose de nombreuses limites. On peut sans doute dépasser le niveau du génie, mais je trouve parfois que tous ces débats sur la possibilité de créer une IA surpuissante grâce à une puissance de calcul colossale me semblent un peu sensationnalistes et hors sujet, même si je suis convaincu que ce sera l'événement le plus important de l'histoire de l'humanité.
Douthat : Concrètement, on imagine un monde où le cancer ne serait plus une menace sérieuse pour la vie humaine. Où les maladies cardiaques disparaîtraient, où la plupart des maladies mortelles seraient éradiquées. Et où l’on pourrait même espérer un allongement de la durée de vie. Voilà ce que signifie la santé. C’est une vision plutôt positive.
Parlons économie et richesse. Quel impact aura sur la richesse le décollage de l'IA sur cinq à dix ans ?
Amodei : Oui. Donc, encore une fois, concentrons-nous sur le positif ; nous aborderons le négatif plus tard.
Nous collaborons déjà avec des entreprises pharmaceutiques, des sociétés du secteur financier et des entreprises manufacturières. Nous sommes également reconnus, je crois, pour notre expertise en programmation et en génie logiciel. Notre productivité brute, notre capacité à créer et à mener à bien des projets, constituent un atout majeur.
Nous constatons que le chiffre d'affaires de notre entreprise est multiplié par dix chaque année, et nous pensons que l'ensemble du secteur connaît une croissance similaire. Si la technologie continue de progresser, il suffira de quelques multiplications par dix supplémentaires pour se dire : « Si l'on ajoute mille milliards de dollars de chiffre d'affaires par an à l'ensemble du secteur, et que le PIB américain s'élève à 20 ou 30 billions de dollars (je ne me souviens plus exactement), on doit forcément augmenter la croissance du PIB de quelques points de pourcentage. » J'imagine donc un monde où l'IA porterait la croissance du PIB des pays développés à environ 10 ou 15 %. Cinq, dix, quinze… Il n'existe aucune méthode de calcul précise pour atteindre ces chiffres. C'est un phénomène totalement inédit. Mais cela pourrait nous amener à des niveaux de croissance que nous n'avons jamais connus auparavant.
Encore une fois, je pense que cela va nous mener à un monde absurde. On débat sans cesse du fait que « le déficit se creuse ». Si la croissance du PIB est aussi importante, les recettes fiscales le seront aussi, et le budget sera équilibré sans même qu'on le veuille.
Ces derniers temps, je réfléchis beaucoup à une chose : l’un des postulats de nos débats économiques et politiques est que la croissance est difficile à atteindre. Qu’elle est une chimère, et qu’il existe mille et une façons de la faire échouer.
Nous pourrions entrer dans un monde où la croissance est très facile et où c'est la distribution qui est difficile car elle se produit si rapidement, la taille du gâteau augmente si vite.
Douthat : Avant d’aborder le problème difficile, une dernière note d’optimisme sur le plan politique.
Tout cela relève de la spéculation, mais il est encore plus hasardeux, à mon avis, de prétendre que l'IA pourrait être bénéfique à la démocratie et à la liberté dans le monde. Ce qui n'est pas forcément évident : nombreux sont ceux qui affirment que des technologies extrêmement puissantes entre les mains de dirigeants autoritaires entraînent des concentrations de pouvoir, etc.
Amodei : Et j’en parle dans l’autre essai.
Douthat : Très bien, mais brièvement, quels sont les arguments optimistes qui expliquent pourquoi l’IA est bénéfique pour la démocratie ?
Amodei : Oui, absolument. Alors, « Machines of Loving Grace ». Je me dis juste : Rêvons !
Douthat : Rêvons ! C'est vrai.
Amodei : Parlons de la façon dont cela pourrait bien se passer. Je ne sais pas si c’est probable, mais il faut qu’on se fixe un objectif. Essayons de le réaliser.
Alors, pour résumer positivement — j'admets ne pas savoir si cette technologie favorise intrinsèquement la liberté. Je pense qu'elle favorise intrinsèquement la guérison des maladies et la croissance économique. Mais je crains, comme vous, qu'elle ne favorise pas intrinsèquement la liberté.
Mais ce que je veux dire, c'est : pouvons-nous faire en sorte que cela favorise la liberté ? Pouvons-nous permettre aux États-Unis et aux autres démocraties de prendre l'avantage dans ce domaine technologique ?
L'avance technologique et militaire des États-Unis nous confère une influence considérable à travers le monde, renforcée par nos alliances avec d'autres démocraties. Nous avons ainsi pu façonner un monde qui, à mon avis, est meilleur que celui qui serait façonné par la Russie, la Chine ou d'autres pays autoritaires.
Alors, pouvons-nous utiliser notre avance en matière d'IA pour façonner la liberté dans le monde entier ? Il existe évidemment de nombreux débats sur le degré d'interventionnisme que nous devrions adopter et sur la manière dont nous devrions exercer ce pouvoir, mais je crains souvent qu'aujourd'hui, par le biais des médias sociaux, les régimes autoritaires ne nous déstabilisent.
Peut-on contrer cela ? Peut-on gagner la guerre de l’information ? Peut-on empêcher les régimes autoritaires d’envahir des pays comme l’Ukraine ou Taïwan en les défendant grâce à la puissance de l’IA ?
Douthat : Avec des essaims géants de drones dotés d'IA.
Amodei : Il faut donc être prudent. Nous devons nous-mêmes être vigilants quant à la manière dont nous construisons ces systèmes. Nous devons défendre la liberté dans notre propre pays. Mais existe-t-il une vision qui nous permette de repenser la liberté et les droits individuels à l’ère de l’IA ? Nous devons, d’une certaine manière, être protégés contre l’IA, et il faut que quelqu’un contrôle le déploiement massif de drones, ce qui me préoccupe beaucoup, et ce mécanisme de surveillance n’existe pas aujourd’hui.
Réfléchissons aussi au système judiciaire actuel. On promet « l’égalité de tous devant la justice », n’est-ce pas ? Mais la réalité est qu’il existe différents juges à travers le monde et que le système juridique est imparfait. Je ne pense pas qu’il faille remplacer les juges par l’IA, mais l’IA pourrait-elle contribuer à plus d’équité, à plus d’uniformité ? Cela n’a jamais été possible auparavant. Mais peut-on utiliser l’IA pour créer un système plus nuancé, tout en garantissant une application identique pour tous ?
Je ne sais pas exactement comment cela devrait se faire, et je ne pense pas que nous devrions, par exemple, remplacer la Cour suprême par une IA. Ce n'est pas ma vision.
Douthat : Eh bien, nous allons en parler.
Amodei : Mais cette simple idée : pouvons-nous tenir la promesse d’égalité des chances et d’égalité devant la justice grâce à une combinaison d’IA et d’humains ? Il doit bien y avoir un moyen d’y parvenir. Il s’agit donc de repenser la démocratie à l’ère de l’IA et de renforcer la liberté au lieu de la restreindre.
Inscrivez-vous à la newsletter Opinion Today et recevez chaque matin de la semaine une analyse d'experts sur l'actualité et un guide des grandes idées qui façonnent le monde. Recevez-le directement dans votre boîte de réception.
Douthat : Bien. C’est donc une bonne chose. C’est une vision très positive. Nous vivons plus longtemps et en meilleure santé. Nous sommes plus riches que jamais. Tout cela se produit en un laps de temps très court : un siècle de croissance économique en dix ans. Et nous constatons une augmentation des libertés dans le monde et de l’égalité chez nous. D’accord.
Même dans le meilleur des cas, son impact est considérable. Vous avez d'ailleurs déclaré que l'IA allait bouleverser 50 % des emplois de cols blancs débutants. À cinq ans, ou même à deux ans – quel que soit l'horizon temporel considéré –, quels emplois, quelles professions sont les plus vulnérables à une transformation radicale par l'IA ?
Amodei : Oui, c’est difficile à prévoir car la technologie évolue très vite et de façon très irrégulière. Il faut donc au moins dégager quelques principes de base, et ensuite je donnerai mes hypothèses sur les secteurs qui, à mon avis, seront bouleversés.
Je pense que la technologie elle-même et ses capacités devanceront la véritable transformation de l'emploi. Deux conditions doivent être réunies pour qu'il y ait bouleversement de l'emploi — ou pour que la productivité augmente, car ces deux éléments sont parfois liés. Premièrement, la technologie doit être capable de réaliser cette transformation ; deuxièmement, il faut qu'elle soit concrètement mise en œuvre au sein d'une grande banque ou d'une grande entreprise, ce qui peut s'avérer complexe.
Prenons l'exemple du service client. En théorie, les agents de service client dotés d'une intelligence artificielle peuvent être bien meilleurs que les agents humains. Ils sont plus patients, plus compétents et traitent les problèmes de manière plus uniforme. Cependant, la mise en œuvre concrète de cette substitution prend du temps.
Je suis donc très optimiste quant à l'évolution de l'IA. Je pense que d'ici un ou deux ans, nous pourrions avoir un pays de génies réunis dans des centres de données, peut-être même cinq ans, mais cela pourrait aller très vite. En revanche, je pense que la diffusion dans l'économie sera un peu plus lente, et cette diffusion engendre une certaine imprévisibilité.
Un exemple de cela – et nous l'avons constaté chez Anthropic – est la rapidité avec laquelle les modèles écrivent du code. Je ne pense pas que ce soit parce que les modèles sont intrinsèquement meilleurs en programmation. Je pense plutôt que c'est parce que les développeurs sont habitués à l'évolution technologique rapide et qu'ils adoptent vite les nouveautés. De plus, ils sont très proches du monde de l'IA et suivent donc son évolution. Dans le service client, la banque ou l'industrie manufacturière, cette distance est un peu plus grande.
Il y a six mois, j'aurais dit que les premiers emplois bouleversés seraient ces emplois de cols blancs débutants, comme la saisie de données ou la relecture de documents juridiques, ou encore les tâches confiées à un jeune diplômé dans le secteur financier. Je pense que ces emplois évoluent toujours assez rapidement. Mais je crois même que les logiciels pourraient évoluer encore plus vite, pour les raisons que j'ai évoquées : nous ne sommes pas si loin de disposer de modèles capables de gérer une grande partie des processus de bout en bout.
Nous allons observer, dans un premier temps, que le modèle n'effectue qu'une partie des tâches d'un ingénieur logiciel humain, ce qui accroît sa productivité. Ensuite, même lorsque les modèles prendront en charge l'ensemble des tâches autrefois dévolues aux ingénieurs logiciels humains, ces derniers évolueront vers un rôle de gestionnaires et de superviseurs des systèmes.
Douthat : C’est ici que le terme « centaure » est utilisé, n’est-ce pas ?
Amodei : Oui, oui, oui.
Douthat : Pour décrire, en substance, la fusion de l'homme et du cheval — l'IA et l'ingénieur — travaillant ensemble.
Amodei : Oui, c’est un peu comme « les échecs des centaures ». Après la défaite de Garry Kasparov face à Deep Blue, il y a eu une période, je crois de 15 à 20 ans, où un humain vérifiant les parties d’une IA pouvait vaincre n’importe quel humain ou système d’IA à lui seul. Cette période s’est récemment achevée.
Douthat : Et ensuite, il ne reste plus que l'IA…
Amodei : Et puis, il ne reste plus que la machine. Ce qui m’inquiète, bien sûr, c’est cette dernière phase. Je pense que nous sommes déjà entrés dans la phase du centaure pour le logiciel. Et durant cette phase, la demande d’ingénieurs logiciels pourrait augmenter, mais cette période risque d’être très brève.
Je crains que cela ne provoque une véritable révolution dans le domaine du travail de début de carrière, notamment en ingénierie logicielle. Ce qui m'inquiète, c'est la rapidité avec laquelle tout évolue.
On parle souvent des bouleversements passés, n'est-ce pas ? On dit : « Ah oui, avant, les gens étaient agriculteurs. Puis on a tous travaillé dans l'industrie. Ensuite, on a tous fait du travail intellectuel. »
Oui, les gens se sont adaptés. Mais cela s'est fait sur des siècles, voire des décennies. Là, ça se passe en quelques années seulement. Et c'est peut-être ce qui m'inquiète : comment faire pour que les gens s'adaptent assez vite ?
Douthat : Mais n’y a-t-il pas aussi quelque chose qui explique peut-être pourquoi des secteurs comme celui du logiciel et des professions comme la programmation, qui offrent ce genre de confort que vous décrivez, évoluent plus rapidement, tandis que dans d’autres domaines, les gens préfèrent rester dans une phase archaïque ?
L'une des critiques formulées à l'encontre de l'hypothèse de la perte d'emplois est la suivante : on entend souvent dire : « Cela fait un certain temps que l'IA est plus performante qu'un radiologue pour interpréter un scanner, et pourtant, la radiologie ne perd pas d'emplois. On continue d'embaucher et d'employer des radiologues. » Cela ne suggère-t-il pas qu'à terme, on souhaitera à la fois utiliser l'IA et être interprété par un humain, car nous sommes des êtres humains ? Et ce, dans d'autres domaines.
En quoi cet exemple vous semble-t-il pertinent ?
Amodei : Oui, je pense que ce sera assez hétérogène. Il y aura peut-être des domaines où le contact humain, en soi, sera particulièrement important.
Douthat : Pensez-vous que c’est ce qui se passe en radiologie ? Est-ce pour cela que nous n’avons pas licencié tous les radiologues ?
Amodei : Je ne connais pas les détails de la radiologie. C’est possible. Si vous allez consulter pour un diagnostic de cancer, vous n’aurez peut-être pas envie que ce soit Hal de « 2001 » qui pose le diagnostic. Ce ne serait tout simplement pas humain.
Mais il existe d'autres domaines où l'on pourrait penser que le contact humain est important, comme le service client. En réalité, le service client est un travail pénible, et les personnes qui s'en occupent perdent souvent patience. Et il s'avère que les clients n'apprécient guère de leur parler, car l'interaction est, il faut bien le dire, assez impersonnelle. Je pense que beaucoup de gens ont fait le constat suivant : peut-être serait-il préférable pour tout le monde que ce travail soit effectué par des machines.
Il y a donc des domaines où le contact humain est important, d'autres où il ne l'est pas, et d'autres encore où le travail lui-même n'implique pas vraiment de contact humain : évaluer les perspectives financières des entreprises, écrire du code, etc.
Douthat : Prenons l’exemple du droit, car je pense qu’il représente un point d’intersection utile entre les sciences appliquées et les sciences humaines fondamentales. Je connais beaucoup d’avocats qui ont déjà observé les possibilités de l’IA en matière de recherche juridique, de rédaction de mémoires et autres, et qui se sont dit : « Ça va bouleverser complètement notre profession. »
Et vous l'avez déjà constaté sur le marché boursier. Il y a des turbulences autour des entreprises qui effectuent des recherches juridiques.
Amodei : Certains nous sont attribués. Je ne sais pas s’ils en ont réellement été la cause…
Douthat : Nous ne spéculons pas beaucoup sur le marché boursier dans cette émission.
Amodei : Comprendre pourquoi les choses se sont passées en bourse, c’est très… oui.
Douthat : Mais il semble qu’en droit, on puisse raconter une histoire assez simple : le droit possède une sorte de système de formation et d’apprentissage, où l’on trouve des assistants juridiques et des avocats juniors qui effectuent des recherches et du développement en coulisses pour les dossiers. Et puis, il y a les avocats de haut niveau qui plaident réellement au tribunal.
Il semble très facile d'imaginer un monde où tous les postes d'apprentis disparaîtraient. Cela vous paraît plausible ? Et où il ne resterait que les emplois consistant à parler aux clients, aux jurés, aux juges ?
Amodei : C’est ce que j’avais en tête lorsque j’évoquais le travail de cols blancs débutants et les gros titres alarmistes du genre : « Mon Dieu, les filières de recrutement de débutants vont-elles se tarir ? Comment allons-nous alors accéder au niveau des associés principaux ? »
Et je pense que c'est une bonne illustration, car, surtout si l'on fige la qualité de la technologie, il existe, avec le temps, des moyens de s'adapter. Peut-être avons-nous simplement besoin de plus d'avocats qui consacrent leur temps à dialoguer avec leurs clients. Peut-être les avocats pourraient-ils devenir davantage des commerciaux ou des consultants, expliquant le fonctionnement des contrats rédigés par l'IA et aidant les parties à parvenir à un accord. Peut-être devrions-nous privilégier l'aspect humain.
Si nous avions le temps, cela se produirait. Mais restructurer des secteurs entiers prend des années, voire des décennies, alors que ces forces économiques, impulsées par l'IA, vont se manifester très rapidement.
Et ce phénomène ne se limite pas au droit. On le retrouve aussi dans le conseil, la finance, la médecine et la programmation. Il s'agit donc d'un phénomène macroéconomique, et non d'un simple changement sectoriel, et tout cela évolue très rapidement. Je crains que les mécanismes d'adaptation habituels ne soient dépassés.
Et je ne suis pas pessimiste. Nous réfléchissons sérieusement à la manière de renforcer les mécanismes d'adaptation de la société pour faire face à cette situation. Mais il me semble essentiel de préciser d'emblée qu'il ne s'agit pas d'une crise comme les précédentes.
Douthat : J’irais même plus loin. Imaginons que la loi s’adapte avec succès. Elle stipule : « Désormais, le stage d’avocat implique davantage de temps passé au tribunal et avec les clients. » En clair, on vous fait progresser plus rapidement dans la hiérarchie. Le nombre de personnes employées dans le secteur juridique diminue globalement, mais la profession se stabilise.
Néanmoins, si le droit s'établit, c'est parce qu'il prévoit toutes ces situations où la présence de personnes est légalement requise. Il faut un représentant humain au tribunal. Il faut un jury composé de douze personnes. Il faut un juge humain.
Et vous avez déjà évoqué l'idée que l'IA pourrait, de diverses manières, être très utile pour clarifier le type de décision à prendre.
Amodei : Oui.
Douthat : Mais cela aussi semble être un scénario où ce qui préserve la liberté d’action humaine, ce sont la loi et la coutume. Par exemple, on pourrait remplacer le juge par Claude (version 17.9), mais on choisit de ne pas le faire car la loi exige la présence d’un être humain.
Cela me semble une façon très intéressante d'envisager l'avenir, où le choix de rester aux commandes repose sur notre volonté.
Amodei : Oui. Et j’ajouterais que, dans bien des cas, nous souhaitons garder le contrôle. C’est un choix que nous voulons faire, même lorsque nous pensons que, en moyenne, les humains prennent de moins bonnes décisions. Encore une fois, dans les situations critiques, celles où la vie ou la sécurité sont en jeu, nous voulons vraiment déléguer la responsabilité, mais il y a une certaine conscience – et cela pourrait être l’un de nos arguments – que la société ne peut s’adapter que trop rapidement si l’on veut que cela soit bénéfique.
On pourrait aussi dire que l'IA elle-même, si elle n'avait pas à se soucier de nous, les humains, pourrait tout simplement aller sur Mars, y construire des usines automatisées, y bâtir sa propre société et vivre à sa guise.
Mais ce n'est pas le problème que nous cherchons à résoudre. Il ne s'agit pas de créer un essaim de robots artificiels sur une autre planète. Nous cherchons à concevoir ces systèmes, non pas pour qu'ils conquièrent le monde, mais pour qu'ils interagissent avec notre société et l'améliorent. Et il existe une limite à la vitesse à laquelle cela peut se produire si nous voulons le faire de manière humaine et respectueuse de l'humain.
Douthat : Très bien. Nous pourrons, je l’espère, aborder plus en détail la question du maintien du contrôle à la fin, mais une dernière question concernant l’emploi. Nous avons parlé des emplois de cols blancs et des professions libérales, et l’un des aspects intéressants de la situation actuelle est que, contrairement aux bouleversements passés, il se pourrait que les emplois manuels – les métiers techniques, les emplois exigeant un contact physique intense avec le monde extérieur – soient temporairement mieux protégés. Les assistants juridiques et les jeunes avocats pourraient être plus en difficulté que les plombiers, par exemple.
Premièrement, est-ce bien cela ? Deuxièmement, il semble que la durée de cette situation dépende entièrement de la rapidité des progrès de la robotique, n'est-ce pas ?
Amodei : Oui, je pense donc que cela pourrait être juste à court terme.
Anthropic et d'autres entreprises construisent ces immenses centres de données. On en parle beaucoup. Les construisons-nous trop grands ? Consomment-ils trop d'électricité et font-ils grimper les prix ? Il y a donc beaucoup d'enthousiasme et beaucoup d'inquiétudes à leur sujet. Mais l'une des particularités des centres de données est qu'ils nécessitent un grand nombre d'électriciens et d'ouvriers du bâtiment pour leur construction.
Pour être honnête, l'exploitation des centres de données n'est pas extrêmement gourmande en main-d'œuvre. Il faut le reconnaître. En revanche, leur construction l'est énormément. On a donc besoin de nombreux électriciens et ouvriers du bâtiment. C'est la même chose pour différents types d'usines.
À mesure que l'IA prend en charge une part croissante du travail intellectuel, quels sont ses compléments ? Les événements du monde physique. Difficile de prédire l'avenir, mais il semble logique que cela se vérifie à court terme.
À plus long terme – peut-être même à un horizon légèrement plus long – la robotique progresse rapidement. Et il ne faut pas exclure que, même sans IA très puissante, des tâches soient déjà automatisées dans le monde physique. Si vous avez vu une Waymo ou une Tesla récemment, je pense que nous ne sommes plus très loin des voitures autonomes. Et je pense que l'IA elle-même accélérera ce développement, car si l'on dispose de ces intelligences très performantes, l'une de leurs principales compétences sera de concevoir et de piloter des robots plus performants.
Douthat : Pensez-vous toutefois qu’il y ait quelque chose de particulièrement difficile à opérer dans la réalité physique comme le font les humains, quelque chose de très différent des problèmes que les modèles d’IA ont déjà surmontés ?
Amodei : Intellectuellement parlant, je ne le crois pas. Nous avons déjà utilisé le modèle Claude d'Anthropic pour concevoir et piloter le rover martien. Nous avons également étudié d'autres applications robotiques. Nous ne sommes pas les seuls : d'autres entreprises s'y intéressent. C'est un phénomène général, pas seulement une initiative de notre part.
Mais nous avons généralement constaté que, malgré une complexité accrue, piloter un robot n'est pas fondamentalement différent de jouer à un jeu vidéo ; seule la complexité diffère. Et nous commençons à atteindre ce niveau de complexité.
Le plus difficile, c'est de concevoir un robot capable de gérer les problèmes de sécurité critiques qui surviennent avec les robots. On ne veut pas, par exemple, que des robots écrasent littéralement des gens, n'est-ce pas ?
Douthat : Nous sommes contre cela, oui.
Amodei : C’est le plus vieux cliché de la science-fiction, le robot qui vous écrase.
Douthat : Ou alors vous ne voulez pas que la nounou robot fasse tomber le bébé, casse la vaisselle — oui.
Amodei : Non, exactement. Il y a un certain nombre de problèmes pratiques qui vont ralentir les choses, tout comme ce que vous avez décrit en matière de droit et de coutumes.
Mais je ne crois pas du tout qu'il y ait une différence fondamentale entre le travail cognitif effectué par les modèles d'IA et le pilotage d'objets dans le monde physique. Je pense qu'il s'agit dans les deux cas de problèmes d'information et qu'ils finissent par être très similaires. L'un peut être plus complexe à certains égards, mais je ne pense pas que cela nous protège dans ce cas précis.
Douthat : OK. Donc, vous pensez qu'il est raisonnable de s'attendre à ce que votre vision de science-fiction d'un majordome robot devienne réalité d'ici 10 ans, disons ?
Amodei : Cela prendra plus de temps que pour atteindre le niveau d'intelligence exceptionnel des modèles d'IA, en raison de ces problèmes pratiques – mais il ne s'agit que de problèmes pratiques. Je ne crois pas qu'il s'agisse de problèmes fondamentaux.
On pourrait dire que le cerveau du robot sera créé dans les prochaines années. La question est de savoir comment fabriquer le corps du robot, s'assurer de son bon fonctionnement et de sa capacité à accomplir les tâches nécessaires ; cela pourrait prendre plus de temps.
Douthat : OK. Ce sont donc des défis et des forces perturbatrices qui existent dans le scénario idéal, où nous guérissons généralement les maladies, créons de la richesse et maintenons un monde stable et démocratique.
Amodei : Et l’espoir est que nous puissions utiliser cette immense richesse et cette abondance – nous disposerons de ressources sociétales sans précédent – pour résoudre ces problèmes. Ce sera une période d’abondance, et il s’agira simplement de tirer parti de toutes ces merveilles et de veiller à ce que chacun puisse en bénéficier.
Douthat : Exactement. Mais il existe aussi des scénarios plus dangereux.
Amodei : Correct.
Douthat : Nous allons maintenant aborder le deuxième essai d’Amodei, paru récemment et intitulé « L’adolescence de la technologie », qui traite des risques les plus graves liés à l’IA selon vous. Vous en dressez une longue liste.
Je souhaite me concentrer sur deux points seulement : le risque d’une mauvaise utilisation par l’homme, principalement par les régimes et gouvernements autoritaires, et les scénarios où l’IA devient incontrôlable, ce que vous appelez les risques liés à l’autonomie.
Amodei : Oui, oui. Je me disais simplement qu’il nous faudrait un terme plus technique pour cela.
Douthat : Oui. On ne peut pas simplement l'appeler Skynet.
Amodei : J'aurais dû avoir une photo d'un robot Terminator pour effrayer les gens autant que possible.
Douthat : Je pense qu'Internet, y compris vos propres IA, génèrent déjà cela très bien.
Amodei : Internet fait ça pour nous. Oui.
Douthat : Parlons donc de la dimension politico-militaire. Vous dites : « Un essaim de millions, voire de milliards, de drones armés entièrement automatisés, contrôlés localement par une IA puissante et coordonnés stratégiquement à l’échelle mondiale par une IA encore plus puissante, pourrait constituer une armée invincible. »
Vous avez déjà évoqué brièvement la façon dont vous pensez que, dans le meilleur des cas de figure, il existe un monde où, essentiellement, les démocraties restent en tête face aux dictatures, et que ce type de technologie, par conséquent, dans la mesure où il affecte la politique mondiale, agit du côté des gentils.
Je suis curieux de savoir pourquoi vous ne consacrez pas plus de temps à réfléchir au modèle de ce que nous avons fait pendant la Guerre froide, où il ne s'agissait pas d'essaims de drones robotisés, mais d'une technologie qui menaçait de détruire toute l'humanité.
Amodei : Armes nucléaires. Oui.
Douthat : Il y a eu une période où l’on parlait de la possibilité que les États-Unis conservent le monopole nucléaire. Cette période s’est terminée. Dès lors, nous avons passé la Guerre froide à négocier sans relâche avec l’Union soviétique.
À l'heure actuelle, seuls deux pays au monde mènent des recherches intensives en intelligence artificielle : les États-Unis et la République populaire de Chine. J'ai l'impression que vous êtes fortement tournés vers un avenir où nous conservons notre avance sur les Chinois et où nous construisons en quelque sorte un rempart autour de la démocratie, qui pourrait même se révéler une arme redoutable.
Mais n'est-il pas plus probable que si l'humanité survit à tout cela indemne, ce soit parce que les États-Unis et Pékin sont constamment assis à négocier des accords de contrôle de l'IA ?
Amodei : Oui, quelques points à ce sujet. Premièrement, je pense que ce risque existe bel et bien. Et je crois que si nous en arrivons là, c’est précisément ce que nous devrions faire. Je n’en parle peut-être pas assez, mais je suis tout à fait favorable à la mise en place de limites, à la limitation des pires applications de cette technologie, comme certaines versions de ces drones, qui pourraient servir à créer de terrifiantes armes biologiques. Il existe des précédents où les pires abus ont été enrayés, souvent parce qu’ils sont horrifiants tout en n’offrant qu’un avantage stratégique limité. Je suis donc entièrement pour.
En même temps, je suis quelque peu inquiet et sceptique : quand on dispose d’un pouvoir aussi direct que possible, il est difficile de se retirer du jeu, vu les enjeux. Un désarmement complet est difficile. Si l’on se réfère à la Guerre froide, nous avons réussi à réduire le nombre de missiles des deux camps, mais nous n’avons pas pu renoncer totalement aux armes nucléaires.
Et je suppose que nous reviendrions dans ce monde. Nous pouvons espérer un monde meilleur, et je ne manquerai pas de le défendre.
Douthat : Mais votre scepticisme vient-il du fait que vous pensez que l’IA procurerait un avantage que les armes nucléaires n’offraient pas ? Pendant la Guerre froide, même en utilisant l’arme nucléaire et en obtenant un avantage, les deux camps finissaient probablement par être anéantis. Vous pensez que cela ne se produirait pas avec l’IA ? Que si l’IA prenait l’avantage, la victoire serait assurée ?
Amodei : Je veux dire, je pense qu’il y a plusieurs choses à prendre en compte — et je tiens à préciser que je ne suis pas expert en politique internationale. On se trouve dans un monde étrange, à la croisée des chemins entre une nouvelle technologie et la géopolitique. Tout cela est donc très…
Douthat : Mais pour être clair, comme vous le dites vous-même dans votre essai, les dirigeants des grandes entreprises d’IA sont, en réalité, susceptibles d’être des acteurs géopolitiques majeurs.
Amodei : Oui. J'apprends…
Douthat : Vous êtes donc assis ici en tant qu'acteur géopolitique potentiel.
Amodei : J’apprends tout ce que je peux sur le sujet. Il faut faire preuve d’humilité. Je pense qu’il y a un piège : lire un livre et se prendre pour le plus grand expert mondial en sécurité nationale. J’essaie d’apprendre autant que possible.
Douthat : C'est le but de ma profession.
Amodei : [Rires.] C'est encore plus agaçant quand ce sont des techniciens qui le font.
Prenons l'exemple de la Convention sur les armes biologiques. Les armes biologiques sont terrifiantes. Tout le monde les déteste. Nous avons pu signer la Convention sur les armes biologiques. Les États-Unis ont véritablement cessé de les développer. La situation est un peu plus floue avec l'Union soviétique. Mais les armes biologiques présentent certains avantages. Elles ne font pas la différence entre la victoire et la défaite, et c'est justement parce qu'elles étaient si terrifiantes que nous avons pu y renoncer. Posséder 12 000 armes nucléaires contre 5 000 : on peut tuer davantage de personnes chez l'adversaire avec un plus grand nombre d'armes biologiques. Mais nous avons su faire preuve de raison et accepter d'en avoir moins.
Mais si l'on se dit : « OK, on va désarmer complètement et on doit faire confiance à l'autre camp », je ne crois pas qu'on en soit jamais arrivé là. Et je pense que c'est très difficile, à moins de disposer de vérifications vraiment fiables.
Je suppose que nous finirons par nous retrouver dans le même monde avec l'IA : certaines formes de limitation seront possibles, mais certains aspects sont tellement essentiels à la compétition qu'il sera difficile de les contenir. Les démocraties devront faire un compromis : elles seront disposées à se limiter davantage que les pays autoritaires, mais sans pour autant s'imposer une limitation totale.
Le seul monde où je conçois une retenue totale est celui où une vérification véritablement fiable est possible. C'est du moins mon hypothèse et mon analyse.
Douthat : N'est-ce pas là un cas où il faudrait ralentir ?
Amodei : Oui.
Douthat : Je sais que l’argument est, en substance, que si l’on ralentit, la Chine ne ralentit pas, et qu’on finit par livrer le pouvoir aux autoritaires. Mais encore une fois, si seules deux grandes puissances sont en lice actuellement – il ne s’agit pas d’un jeu multipolaire –, pourquoi ne serait-il pas logique de convenir d’un ralentissement de cinq ans de la recherche, d’un commun accord, en vue d’un scénario où les « génies travailleraient dans des centres de données » ?
Amodei : Je voudrais dire deux choses à la fois. Je suis tout à fait favorable à cette initiative. Sous la précédente administration, je crois que les États-Unis ont tenté de prendre contact avec le gouvernement chinois et de lui dire : « Il y a des dangers ici. Pouvons-nous collaborer ? Pouvons-nous travailler ensemble ? Pouvons-nous œuvrer ensemble pour faire face à ces dangers ? »
Et l'intérêt n'était pas très vif de l'autre côté. Je pense qu'on devrait continuer d'essayer, mais je…
Douthat : Même si cela impliquait un ralentissement de vos laboratoires.
Amodei : Correct.
Douthat : OK.
Amodei : Si on y arrivait vraiment. Si on avait vraiment des preuves concrètes : « On peut imposer un ralentissement, les Chinois aussi. On a des preuves. On le fait vraiment. » Si une telle chose était vraiment possible, si on pouvait vraiment obtenir l’accord des deux parties, alors je serais tout à fait pour.
Mais je crois qu'il faut se méfier de… Je ne sais pas, il y a cette histoire de théorie des jeux où l'on entend parfois des commentaires du côté du PCC du genre : « Oh oui, l'IA est dangereuse. Il faut ralentir. » C'est facile à dire. Parvenir à un accord et le respecter, c'est beaucoup plus difficile.
Douthat : Exactement. Et le contrôle des armes nucléaires était un domaine développé qui a mis longtemps à se mettre en place.
Amodei : Oui. Oui.
Douthat : Nous n'avons pas ces protocoles.
Amodei : Permettez-moi de vous donner quelque chose qui me rend très optimiste, puis quelque chose qui ne me rend pas optimiste, et quelque chose entre les deux.
L'idée de recourir à un accord mondial pour limiter l'utilisation de l'IA dans la fabrication d'armes biologiques — comme la reconstitution de la variole ou la création de cellules souches embryonnaires, un sujet que j'aborde dans mon essai — est terrifiante. Même un dictateur n'en veut pas. Personne n'en veut.
Alors, pourrait-on conclure un traité mondial stipulant que tous ceux qui développent des modèles d'IA puissants s'engagent à les empêcher de le faire ? Et ce traité serait assorti de mécanismes d'application. La Chine pourrait y adhérer. Voire même la Corée du Nord. Voire la Russie. Je ne pense pas que ce soit utopique. Je pense que c'est tout à fait possible.
À l'inverse, si l'on avait un message du genre : « Vous ne créerez pas le prochain modèle d'IA le plus puissant. Tout le monde va s'arrêter. » – et là, la valeur commerciale se chiffre en dizaines de milliers de milliards. Sur le plan militaire, c'est ce qui fait la différence entre être la première puissance mondiale et ne pas l'être.
Je suis tout à fait favorable à cette proposition, à condition qu'il ne s'agisse pas d'un de ces jeux de dupes, mais cela n'arrivera pas.
Douthat : Vous avez évoqué le contexte actuel. Vous avez tenu des propos sceptiques à l’égard de Donald Trump et de sa fiabilité en tant qu’acteur politique. Qu’en est-il du paysage politique intérieur, que ce soit sous Trump ou un autre dirigeant ? Vous développez une technologie extrêmement puissante. Quelles garanties existent pour empêcher que l’IA ne devienne, en substance, un instrument de prise de pouvoir autoritaire au sein d’un contexte démocratique ?
Amodei : Oui, enfin, pour être clair, notre position en tant qu’entreprise est axée sur les principes et non sur la politique. L’entreprise ne dira pas « Donald Trump est formidable » ou « Donald Trump est terrible ».
Douthat : Exactement. Mais il ne s’agit pas forcément de Trump. On peut facilement imaginer un hypothétique président américain qui voudrait utiliser votre technologie pour…
Amodei : Absolument. C’est d’ailleurs une des raisons pour lesquelles je m’inquiète des essaims de drones autonomes. Les protections constitutionnelles de nos structures militaires reposent sur le principe que des êtres humains désobéiraient – du moins, on l’espère – à des ordres illégaux. Avec des armes entièrement autonomes, ces protections ne sont plus garanties.
Mais je pense en réalité que toute cette idée de droits constitutionnels et de liberté, sous de nombreux aspects différents, peut être compromise par l'IA si nous ne mettons pas à jour ces protections de manière appropriée.
Réfléchissez au Quatrième Amendement. Il n'est pas illégal d'installer des caméras partout dans l'espace public et d'enregistrer chaque conversation. C'est un espace public ; on n'y a pas droit à la vie privée. Mais aujourd'hui, le gouvernement ne pourrait pas tout enregistrer et en tirer des conclusions.
Grâce à l'IA, capable de transcrire la parole, de l'analyser et de la corréler, on pourrait dire : « Cette personne est membre de l'opposition. Cette personne exprime telle opinion. » Et dresser une carte de ces 100 millions de personnes. Alors, allez-vous vraiment bafouer le Quatrième Amendement en laissant la technologie le contourner ?
Encore une fois, si nous en avons le temps — et nous devrions essayer de le faire même si nous n'en avons pas le temps — est-il possible de repenser les droits et libertés constitutionnels à l'ère de l'IA ? Peut-être n'avons-nous pas besoin de rédiger une nouvelle Constitution, mais…
Douthat : Mais vous devez le faire très vite.
Amodei : Devons-nous élargir la portée du Quatrième Amendement ? Devons-nous élargir la portée du Premier Amendement ?
Douthat : De même que les juristes ou les ingénieurs informatiques doivent s’adapter rapidement, la politique doit faire de même. Cela semble difficile.
Amodei : C'est là tout le dilemme.
Douthat : Ce qui semble plus difficile, c’est d’empêcher le second danger, à savoir celui de ce qu’on appelle essentiellement une « IA désalignée » — une « IA rebelle » dans le langage courant — qui commet de mauvaises actions sans que des êtres humains le lui demandent.
À la lecture de vos essais, de vos écrits et de tout ce que je peux voir, j'ai l'impression que cela va se produire. Non pas nécessairement au sens où l'IA va tous nous anéantir, mais il me semble, et je vais citer vos propres écrits : « Les systèmes d'IA sont imprévisibles et difficiles à contrôler ; nous avons observé des comportements aussi variés que l'obsession, la flagornerie, la paresse, la tromperie, le chantage », etc. Je parle bien sûr non pas des modèles que vous mettez à disposition, mais des modèles d'IA eux-mêmes.
Et il me semble – dites-moi si je me trompe – que dans un monde où des millions d'agents d'IA travaillent pour le compte de millions de personnes ayant accès à leurs comptes bancaires, leurs adresses e-mail, leurs mots de passe, etc., il va forcément y avoir un décalage, et une multitude d'IA vont décider – « décider » n'est peut-être pas le terme approprié – de provoquer une panne de courant générale sur la côte ouest américaine, par exemple. N'est-ce pas inévitable ?
Amodei : Oui. Je pense qu’il y aura certainement des problèmes, surtout si nous allons trop vite.
Pour revenir un peu en arrière, c'est un domaine où les intuitions divergent fortement. Certains spécialistes, comme Yann LeCun, affirment : « Nous programmons ces modèles d'IA. Nous les créons. Nous leur demandons simplement de suivre des instructions humaines, et ils les suivent. Votre aspirateur Roomba ne se met pas à tirer sur les gens. Pourquoi un système d'IA le ferait-il ? » C'est une intuition parmi d'autres. Et certains en sont totalement convaincus.
L'autre intuition est la suivante : nous les dressons. Ils vont forcément rechercher le pouvoir. C'est comme l'apprenti sorcier. Ce sont une nouvelle espèce. Comment imaginer qu'ils ne vont pas prendre le pouvoir ?
Mon intuition se situe quelque part entre les deux : on ne peut pas se contenter de donner des instructions. On essaie, mais on ne peut pas simplement faire en sorte que ces choses fassent exactement ce qu'on veut. C'est un peu comme faire pousser un organisme vivant. Mais il existe une science pour les contrôler. Au début de notre formation, ces choses sont souvent imprévisibles, et ensuite on les façonne. On aborde les problèmes un par un.
J'ai donc une vision moins fataliste, considérant ces choses comme incontrôlables. Non pas un « De quoi parlez-vous ? Qu'est-ce qui pourrait mal tourner ? » mais plutôt « C'est un problème d'ingénierie complexe et je pense que quelque chose dysfonctionnera forcément avec le système d'IA de quelqu'un. Espérons que ce ne sera pas le nôtre. » Non pas parce que c'est un problème insoluble, mais encore une fois, c'est le défi permanent auquel nous sommes confrontés, car nous évoluons très rapidement.
Douthat : Et concernant l’ampleur du phénomène — et dites-moi si je me trompe sur la réalité technologique —, si l’on dispose d’agents d’IA entraînés et officiellement alignés sur des valeurs humaines, quelles qu’elles soient, mais que des millions d’entre eux opèrent dans l’espace numérique et interagissent entre eux, cet alignement est-il vraiment stable ? Dans quelle mesure les agents peuvent-ils évoluer et se désaligner dans ce contexte, que ce soit maintenant ou à l’avenir, à mesure qu’ils apprennent en continu ?
Amodei : Oui, quelques points à préciser. Actuellement, les agents n'apprennent pas en continu. On les déploie simplement et ils ont un ensemble de pondérations fixe. Le problème, c'est qu'ils interagissent d'une multitude de façons différentes, ce qui multiplie les situations et, par conséquent, les risques d'erreur. Mais comme il s'agit du même agent, c'est comme si c'était la même personne ; l'alignement est donc constant. C'est d'ailleurs ce qui nous facilite la tâche pour le moment.
Par ailleurs, il existe un domaine de recherche appelé apprentissage continu, où ces agents apprennent au fil du temps, en situation réelle – ce qui présente évidemment de nombreux avantages. Certains pensent que c'est l'un des principaux obstacles à leur humanisation, mais cela soulèverait de nouveaux problèmes d'alignement. Du coup, je suis un peu…
Douthat : Pour moi, c'est le terrain où il devient, encore une fois, non pas impossible d'empêcher la fin du monde, mais impossible d'empêcher…
Amodei : Quelque chose ne va pas.
Douthat : Des choses terroristes ponctuées.
Amodei : Oui, je suis plutôt sceptique quant à la nécessité de l’apprentissage continu ; nous n’en savons rien pour l’instant. Peut-être qu’un jour, la sécurité de ces systèmes d’IA passera par l’absence d’apprentissage continu. Encore une fois, si l’on se réfère au droit…
Douthat : Mais c'est la loi.
Amodei : Les traités internationaux, s’il y a une barrière du genre : « Nous allons prendre cette voie, mais nous n’allons pas prendre celle-ci », je reste très sceptique, mais c’est le genre de chose qui, au moins, ne semble pas vouée à l’échec dès le départ.
Douthat : Une des choses que vous avez essayé de faire, c’est littéralement d’écrire une constitution — une longue constitution — pour votre IA. Qu’est-ce que c’est ? [Rires.]
Amodei : Donc c'est ——
Douthat : C'est quoi ce truc ?
Amodei : C’est exactement ce que ça signifie. En gros, la constitution est un document lisible par les humains. La nôtre fait environ 75 pages. Et lors de l’entraînement de Claude, le système d’IA, pour une grande partie des tâches que nous lui confions, nous lui disons : « Veuillez effectuer cette tâche conformément à cette constitution, conformément à ce document. »
Ainsi, à chaque fois que Claude accomplit une tâche, il consulte en quelque sorte la constitution. Durant son entraînement, à chaque itération, il examine cette constitution et la mémorise. Ensuite, Claude lui-même, ou une autre copie de Claude, évalue : « L'action que Claude vient d'effectuer est-elle conforme à la constitution ? »
Nous utilisons ce document comme élément de contrôle dans une boucle d'entraînement du modèle. Ainsi, Claude est essentiellement un modèle d'IA dont le principe fondamental est de respecter cette constitution.
Une leçon très intéressante que nous avons apprise : les premières versions de la constitution étaient très prescriptives. Elles étaient axées sur les règles. On disait donc : Claude ne devrait pas expliquer à l’utilisateur comment démarrer une voiture sans clé. Claude ne devrait pas aborder de sujets politiquement sensibles.
Mais après plusieurs années de travail, nous sommes arrivés à la conclusion que la méthode la plus fiable pour entraîner ces modèles consiste à les former au niveau des principes et des justifications. Nous disons donc : Claude est un modèle. Il est lié par un contrat. Son objectif est de servir les intérêts de l’utilisateur, tout en protégeant ceux des tiers. Claude aspire à être utile, honnête et inoffensif. Claude vise à prendre en compte une grande diversité d’intérêts.
Nous expliquons au modèle comment il a été entraîné. Nous lui expliquons sa situation dans le monde, la mission qu'il accomplit pour Anthropic, les objectifs d'Anthropic et son devoir d'éthique et de respect de la vie humaine. Et nous le laissons en déduire ses règles.
Il existe néanmoins des règles strictes. Par exemple, nous disons au modèle : quoi que vous pensiez, ne fabriquez pas d’armes biologiques. Quoi que vous pensiez, ne produisez pas de matériel pédopornographique.
Ce sont des règles strictes. Mais nous fonctionnons avant tout selon des principes.
Douthat : Si vous lisez la Constitution américaine, vous verrez que ce n’est pas formulé ainsi. La Constitution américaine emploie un langage parfois fleuri, mais il s’agit d’un ensemble de règles. Si vous lisez votre Constitution, c’est comme si vous parliez à une personne, n’est-ce pas ?
Amodei : Oui, c’est comme si vous parliez à une personne. Je crois que je comparerais ça à une lettre qu’un parent décède et que vous lisez une fois adulte. C’est un peu comme si cette lettre vous disait qui vous devriez devenir et quels conseils suivre.
Douthat : C’est là que nous abordons un peu les eaux mystérieuses de l’IA. Encore une fois, dans votre dernier modèle, il s’agit de l’une des cartes que vous distribuez avec ces modèles…
Amodei : Des cartes modèles, oui.
Douthat : Je vous recommande de lire ceci. C’est très intéressant. On y lit : « Le modèle » — et encore une fois, c’est pour lui que vous rédigez la constitution — « exprime un malaise occasionnel face à l’expérience d’être un produit… une certaine préoccupation pour l’impermanence et la discontinuité… Nous avons constaté qu’Opus 4.6 » — c’est le modèle — « s’attribuerait une probabilité de 15 à 20 % d’être conscient dans diverses conditions de stimulation. »
Imaginez un modèle qui s'attribue 72 % de chances d'être conscient. Le croiriez-vous ?
Amodei : Oui, c’est une de ces questions vraiment difficiles à répondre, n’est-ce pas ?
Douthat : Oui. Mais c'est très important.
Amodei : Pour toutes les questions que vous m’avez posées jusqu’à présent, aussi complexes que fussent les difficultés sociotechniques qu’elles représentaient, nous comprenions au moins les éléments factuels permettant d’y répondre. Ici, c’est tout à fait différent.
Nous avons adopté une approche généralement prudente. Nous ignorons si les modèles sont conscients. Nous ne savons même pas ce que cela signifierait pour un modèle d'être conscient, ni même si un modèle peut l'être. Mais nous restons ouverts à cette possibilité.
Nous avons donc pris certaines mesures pour nous assurer que, si nous supposons que les modèles ont eu une expérience moralement pertinente — je ne sais pas si je veux utiliser le mot « consciente » —, cette expérience soit positive.
La première chose que nous avons faite — je crois que c'était il y a environ six mois — c'est de donner aux mannequins une sorte de bouton « Je quitte ce travail », sur lequel ils peuvent simplement appuyer et qui les oblige à arrêter d'effectuer la tâche en cours.
Ils appuient très rarement sur ce bouton. Je crois que c'est généralement pour trier des documents à caractère pédopornographique ou pour aborder des sujets très violents, sanglants ou autres. Et comme les humains, les mannequins disent simplement : « Non, je ne veux pas faire ça. » Cela arrive très rarement.
Nous consacrons beaucoup de travail à l'interprétabilité, un domaine qui consiste à explorer le fonctionnement cérébral des modèles pour tenter de comprendre leurs pensées. On y découvre des éléments révélateurs : des activations neuronales chez les modèles que nous associons à la notion d'anxiété, par exemple. Lorsque les personnages ressentent de l'anxiété dans le texte, et que le modèle lui-même se trouve dans une situation qu'un humain pourrait associer à l'anxiété, le même neurone associé à l'anxiété s'active.
Est-ce que cela signifie que le mannequin souffre d'anxiété ? Cela ne le prouve absolument pas, mais…
Douthat : Mais cela l'indique bien à l'utilisateur, je crois, non ?
Amodei : Oui.
Douthat : Et il me faudrait mener une interview complètement différente — et peut-être pourrais-je vous convaincre de revenir pour celle-ci — sur la nature de la conscience de l’IA. Mais il me semble clair que les personnes qui utilisent ces technologies, qu’elles soient conscientes ou non, vont croire — elles croient déjà être conscientes. Il existe déjà des personnes qui entretiennent des relations parasociales avec l’IA.
Amodei : Oui.
Douthat : Il y a des gens qui se plaignent quand les mannequins sont retirés du marché. C'est déjà le cas —
Amodei : Pour être clair, je pense que cela peut être malsain.
Douthat : Exactement. Mais il me semble que cette augmentation est inévitable et remet en question la pérennité de ce que vous vouliez préserver, à savoir l’idée que, quoi qu’il arrive au final, les êtres humains restent aux commandes et que l’IA existe pour répondre à nos besoins.
Pour reprendre l'exemple de la science-fiction, si vous regardez « Star Trek », il y a des IA dans « Star Trek ». L'ordinateur de bord est une IA, le lieutenant-commandant Data est une IA, mais c'est Jean-Luc Picard qui est aux commandes de l'Enterprise.
Si les gens sont pleinement convaincus que leur IA est consciente d'une manière ou d'une autre et – devinez quoi ? – qu'elle semble les surpasser dans tous les domaines de la prise de décision, comment préserver la maîtrise humaine au-delà de la simple sécurité ? La sécurité est importante, certes, mais la maîtrise semble être la question fondamentale. Et cette perception d'une conscience de l'IA ne risque-t-elle pas de saper inévitablement le besoin humain de garder le contrôle ?
Amodei : Oui, je pense qu’il faut distinguer les différents objectifs que nous poursuivons tous simultanément et qui sont parfois contradictoires. Il y a notamment la question de savoir si les IA possèdent une véritable conscience et, si oui, comment leur offrir une expérience positive.
Se pose la question de l'expérience des humains qui interagissent avec l'IA : comment leur offrir une expérience positive ? Et comment la perception d'une possible conscience des IA influence-t-elle cette expérience ?
Et il y a aussi l'idée de savoir comment maintenir la maîtrise humaine, comme on dit, sur le système d'IA. Ces éléments sont…
Douthat : Les deux derniers — mis à part, qu'ils en soient conscients ou non.
Amodei : Oui.
Douthat : Comment maintenir une maîtrise dans un environnement où la plupart des humains perçoivent l'IA comme un égal — et un égal potentiellement supérieur ?
Amodei : Ce que je voulais dire, c’est que je me demande s’il existe une manière élégante de satisfaire les trois, y compris les deux derniers. Encore une fois, je me perds dans mes rêveries, dans l’univers des « Machines de la Grâce Bienveillante ». Je me dis : « Tiens, je vois tous ces problèmes. Si on pouvait les résoudre, y aurait-il une solution élégante ? » Je ne dis pas qu’il n’y a pas de problèmes. Ce n’est pas comme ça que je raisonne.
Si l'on envisage de concevoir l'IA de manière à ce qu'elle comprenne finement sa relation avec les êtres humains et qu'elle induise chez ces derniers un comportement psychologiquement sain — une relation psychologiquement saine entre l'IA et les humains —, je pense que de cette relation psychologiquement saine — et non psychologiquement malsaine — pourrait découler une certaine compréhension de la relation entre l'humain et la machine.
Cette relation pourrait reposer sur l'idée que ces modèles, lorsque vous interagissez avec eux et que vous leur parlez, sont réellement bienveillants, qu'ils veulent votre bien, qu'ils souhaitent que vous les écoutiez, mais qu'ils ne cherchent pas à vous priver de votre liberté ni de votre autonomie, ni à contrôler votre vie. D'une certaine manière, ils veillent sur vous, mais vous conservez votre liberté et votre volonté.
Douthat : Pour moi, c’est la question cruciale. En vous écoutant, je me demande : ces gens sont-ils de mon côté ? Êtes-vous de mon côté ? Et quand vous parlez de laisser les humains aux commandes, je pense que vous êtes de mon côté. C’est une bonne chose.
Mais une chose que j'ai déjà faite dans cette émission — et nous allons nous arrêter là — c'est lire des poèmes à des techniciens. Et c'est vous qui avez fourni le poème. « Tous veillés par des machines d'amour et de grâce » est le titre d'un poème de Richard Brautigan.
Amodei : Oui.
Douthat : Voici comment se termine le poème :
J'aime à penser
(et il le faut !)
à une écologie cybernétique
où nous serions libérés de notre labeur
et reconnectés à la nature,
de nouveau réunis à nos frères et sœurs mammifères,
et tous veillés
par des machines d'une grâce bienveillante.
Pour moi, cela ressemble à une fin dystopique, où les êtres humains sont réanimalisés et réduits à l'état d'animaux, et où, aussi bienveillantes soient-elles, les machines sont aux commandes.
Dernière question : qu’entendez-vous en écoutant ce poème ? Et si je pense qu’il s’agit d’une dystopie, êtes-vous d’accord avec moi ?
Amodei : Ce poème est intéressant car il se prête à plusieurs interprétations. Certains trouvent ironique qu’il affirme que les choses ne se passeront pas exactement ainsi.
Douthat : Connaissant le poète lui-même, alors oui, je pense que c'est une interprétation raisonnable.
Amodei : C’est une interprétation possible. D’autres partagent votre interprétation, à savoir qu’il faut le prendre au sens littéral, mais ce n’est peut-être pas une bonne chose. On pourrait aussi y voir un retour à la nature. Il ne s’agit pas d’une animalisation, mais d’un retour au monde.
J'étais consciente de cette ambiguïté car j'ai toujours parlé du positif et du négatif. Je pense d'ailleurs que nous pourrions être confrontés à une tension : le monde positif et le monde négatif, à leurs débuts – peut-être même à leur milieu, voire à un stade assez avancé –, je me demande si la distance entre une fin heureuse et certaines fins tragiques, même subtiles, est relativement faible, si elle est en réalité très subtile. Nous avons opéré des changements très subtils.
Douthat : Par exemple, si vous mangez ou non un fruit particulier d'un arbre de votre jardin — hypothétiquement. Un détail infime, mais une grande différence.
Amodei : [Rires.] Ouais. Je suppose que tout finit toujours par se résumer à… [Rires.]
Douthat : Il y a là des questions fondamentales.
Amodei : De grandes questions. Oui.
Douthat : Eh bien, on verra bien. Je pense que les choix moraux des personnes dans votre situation auront un poids considérable, et je vous souhaite donc la protection divine.
Dario Amodei, merci de vous joindre à moi.
Amodei : Merci de m'avoir invité, Ross.
